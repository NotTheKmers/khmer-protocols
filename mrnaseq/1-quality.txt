================================================
1. Quality Trimming and Filtering Your Sequences
================================================

.. shell start

Boot up an m1.xlarge machine from Amazon Web Services running Ubuntu
14.04 LTS (ami-e84d8480); this has about 15 GB of RAM, and 4 CPUs, and
will be enough to complete the assembly of the Nematostella data set.

On the new machine, run the following commands to update the base
software and reboot the machine::

   apt-get update
   apt-get -y install screen git curl gcc make g++ python-dev unzip default-jre \
              pkg-config libncurses5-dev r-base-core r-cran-gplots python-matplotlib\
              sysstat samtools python-pip && shutdown -r now

.. note::

   The raw data for this tutorial is available as public snapshot
   snap-f5a9dea7.

Install software
----------------

.. clean up previous installs if we're re-running this...

.. ::

   echo Removing previous installs, if any.
   rm -fr /usr/local/share/khmer
   rm -fr /root/Trimmomatic-*
   rm -f /root/libgtextutils-*.bz2
   rm -f /root/fastx_toolkit-*.bz2

.. ::

   echo Clearing times.out
   mv -f /root/times.out /root/times.out.bak
   echo 1-quality INSTALL `date` >> /root/times.out

Install `khmer <http://khmer.readthedocs.org>`__ :
::

   cd /usr/local/share
   git clone https://github.com/ged-lab/khmer.git
   cd khmer
   git checkout ngs2014
   make install

Install `FastQC <http://www.bioinformatics.babraham.ac.uk/projects/fastqc/>`__::

   cd /usr/local/share
   curl -O http://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.10.1.zip
   unzip fastqc_v0.10.1.zip
   chmod +x FastQC/fastqc

Install `Trimmomatic <http://www.usadellab.org/cms/?page=trimmomatic>`__ :
::

   cd /root
   curl -O http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/Trimmomatic-0.32.zip
   unzip Trimmomatic-0.32.zip
   cd Trimmomatic-0.32/
   cp trimmomatic-0.32.jar /usr/local/bin
   cp -r adapters /usr/local/share/adapters

In each of these cases, we're downloading the software -- you can use
google to figure out what each package is and does if we don't discuss
it below.  We're then unpacking it, sometimes compiling it (which we
can discuss later), and then installing it for general use.

Find your data
--------------

Either load in your own data (as in :doc:`0-download-and-save`) or
create a volume from snapshot snap-f5a9dea7 and mount it as ``/data``
(again, this is the data from `Tulin et al., 2013
<http://www.evodevojournal.com/content/4/1/16>`__).

Check::

   ls /data

If you see all the files you think you should, good!  Otherwise, debug.

If you're using the Tulin et al. data provided in the snapshot above,
you should see a bunch of files like::

   /data/0Hour_ATCACG_L002_R1_001.fastq.gz

Link your data into a working directory
---------------------------------------

Rather than *copying* the files into the working directory, let's just
*link* them in -- this creates a reference so that UNIX knows where to
find them but doesn't need to actually move them around. :
::

   cd /mnt
   mkdir work
   cd work
   
   ln -fs /data/*.fastq.gz .

(The 'ln' command is what does the linking.)

Now, do an 'ls' to list the files.  If you see only one entry, ``*.fastq.gz``,
then the ln command above didn't work properly.  One possibility is that
your files aren't in /data; another is that they're not named *.fastq.gz.

.. note::

   This protocol takes many hours (days!) to run, so you might not want
   to run it on all the data the first time.  If you're using the
   example data, you can work with a subset of it by running this command
   instead of the `ln -fs` command above::

      for i in /data/*.fastq.gz
      do
          gunzip -c $i | head -400000 | gzip > $(basename $i)
      done

   This will pull out the first 100,000 reads of each file (4 lines per record)
   and put them in the current directory, which should be /mnt/work.

OPTIONAL: Evaluate the quality of your files with FastQC
--------------------------------------------------------

If you installed Dropbox, we can use FastQC to look at the quality of your sequences::

   mkdir /mnt/Dropbox/fastqc
   /usr/local/share/FastQC/fastqc *001.fastq.gz --outdir=/mnt/Dropbox/fastqc

The output will be placed under the 'fastqc' directory in your Dropbox
on your local computer; look for the fastqc_report.html files, and
double click on them to load them into your browser.

Find the right Illumina adapters
--------------------------------

You'll need to know which Illumina sequencing adapters were used for
your library in order to trim them off; do ::

   ls /usr/local/share/adapters/

to see which ones are available.  Below, we will use the TruSeq3-PE.fa
adapters.

.. note::

   You'll need to make sure these are the right adapters for your
   data.  If they are the right adapters, you should see that some of
   the reads are trimmed; if they're not, you won't see anything
   get trimmed.

Adapter trim each pair of files
-------------------------------

(From this point on, you may want to be running things inside of
screen, so that you detach and log out while it's running; see
:doc:`../amazon/using-screen` for more information.)

If you're following along using the Nematostella data, you should have a
bunch of files that look like this (use 'ls' to show them):

   ``24HourB_GCCAAT_L002_R1_001.fastq.gz``

Each file with an R1 in its name should have a matching file with an R2 --
these are the paired ends.

.. note::

   You'll need to replace <R1 FILE> and <R2 FILE>, below, with the
   names of your actual R1 and R2 files.  You'll also need to replace
   <SAMPLE NAME> with something that's unique to each pair of files.
   It doesn't really matter what, but you need to make sure it's different
   for each pair of files.

Adapter and quality trim your sequences
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We'll now use Trimmomatic to both adapter-trim and quality-trim your
sequences. We're going to use the following parameters:

* ILLUMINACLIP:barcodes.fa:2:40:15
* LEADING:2 
* TRAILING:2
* SLIDINGWINDOW:4:2
* MINLEN:25

We have a script to write these commands out automatically for each
file.  Run it like so : ::

   cd /mnt/work
   python /usr/local/share/khmer/sandbox/write-trimmomatic.py > trim.sh

Run this, and then look at 'trim.sh' using the 'more' command --::

   more trim.sh

.. ::

   echo 1-quality TRIM `date` >> /root/times.out

If it looks like it contains the right commands, you can run it by doing :
::

   bash trim.sh


Briefly, for each file, trim.sh:

* creates a temporary directory, 'trim/'

* runs 'Trimmomatic' in that directory to trim off the adapters, and then
  puts remaining pairs (most of them!) in s1_pe and s2_pe, and any orphaned
  singletons in s1_se and s2_se.

* interleaves the paired ends and puts them back in the working directory

* combines the orphaned reads and puts them back in the working directory

At the end of this you will have new files ending in ``.pe.qc.fq.gz``
and ``.se.qc.fq.gz``, representing the paired and orphaned trimmed
reads, respectively.

.. ::

   echo 1-quality DONE `date` >> /root/times.out

Finishing up
------------

For the Nematostella data, for *each* of the original input files,
you'll have::

   24HourB_GCCAAT_L002_R1_001.fastq.gz 	      	     - the original data
   24HourB_GCCAAT_L002_R2_001.fastq.gz
   24HourB_GCCAAT_L002_R1_001.pe.qc.fq.gz	     - trimmed data (paired)
   24HourB_GCCAAT_L002_R1_001.se.qc.fq.gz	     - trimmed data (orphans)

You no longer need the original data, so you can remove that::
::

   rm *.fastq.gz

and now you should be left with only two files for each sample::

   24HourB_GCCAAT_L002_R1_001.pe.qc.fq.gz   - trimmed PE
   24HourB_GCCAAT_L002_R1_001.pe.qc.fq.gz   - trimmed SE

These are the files you'll need going forward.

Things to think about
~~~~~~~~~~~~~~~~~~~~~

Note that the filenames, while ugly, are conveniently structured with the
history of what you've done.  This is a good idea.

Also note that we've conveniently named the files so that we can remove
the unwanted ones en masse.  This is a good idea, too.

Protecting your files
---------------------

You should make the end product files read-only :
::

   chmod u-w *.qc.fq.gz

to make sure you don't accidentally delete something.

OPTIONAL: Evaluate the quality of your files with FastQC again
--------------------------------------------------------------

If you installed Dropbox, we can once again use FastQC to look at the
quality of your newly-trimmed sequences::

   mkdir /mnt/Dropbox/fastqc
   /usr/local/share/FastQC/fastqc *001.pe.qc.fq.gz --outdir=/mnt/Dropbox/fastqc

Again, the output will be placed under the 'fastqc' directory in your
Dropbox on your local computer; look for the fastqc_report.html files,
and double click on them to load them into your browser.

Workshop instructions
---------------------

If you are running with a data subset for a workshop, do
::

   cp /mnt/work/*.qc.fq.gz /data

to save the QC files for later use.

Saving the files
----------------

At this point, you should save these files, which will be used in two
ways: first, for assembly; and second, for mapping, to do quantitation
and ultimately comparative expression analysis.  You can save them by
doing this::

   mkdir save
   cp *.qc.fq.gz save
   du -sk save

.. shell stop

This puts the data you want to save into a subdirectory named 'save', and
calculates the size.

Now, create a volume of the given size -- divide by a thousand to get
gigabytes, multiply by 1.1 to make sure you have enough room, and then
follow the instructions in :doc:`../amazon/index`.  Once
you've mounted it properly (I would suggest mounting it on /save
instead of /data!), then do ::

   rsync -av save /save

which will copy all of the files over from the ./save directory onto the
'/save' disk.  Then 'umount /save' and voila, you've got a copy of the files!

Next stop: :doc:`2-diginorm`.

